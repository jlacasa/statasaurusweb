{
  "hash": "d4fc9380769e026de7dbf935cdbb938b",
  "result": {
    "markdown": "---\ntitle: \"Code #2\"\nauthor: \"Adrian Correndo & Josefina Lacasa\"\nformat:\n  html:\n    fontsize: 0.8em\n    linestretch: 1\n---\n\n\n\n\n# Introduction to Bayesian Stats\n\nThis is a follow-up article from [Bayes#1](https://adriancorrendo.github.io/statasaurusweb/code_2_bayes_1.html). Still, we do have numerous important concepts in order to understand what the computational codes are doing behind scenes when running a Bayesian analysis.\n\n::: callout-important\n**Today's Topics**:\n\nComputing posterior distributions:\n\n#1. Acceptance/Rejection Sampling Basics:\\\n#2. Markov Chain Monte Carlo (MCMC) More efficient than AR sampling.\n\nPackages for Bayesian analysis in R:\n\n#3. brms\n\n#4. rstan\n\n#5. rjags\n:::\n\n## Computing posterior distributions:\n\n### 1. Acceptance/Rejection Sampling Basics:\n\n1\\. Generate proposal parameter values 2. Generate data with those parameters\\\n3. Compare the simulated data with the observed data = \"difference\" 4. \"**Accept**\" that combination of parameters if the difference \\< predifined acceptable error. \"**Reject**\" if the difference \\> predifined acceptable error.\n\nSee an example:\n\nUsing data of yield vesus plant density in corn:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](code_3_bayes_2_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n$$ y = \\beta_0 + x \\cdot \\beta_1 - x^2 \\cdot \\beta_2$$\n\n\n\n\n\n\n\n\n1.  Generate proposal parameter values **using the prior ditributions**:\n\n\n$$\\beta_0 \\sim uniform(4, 6)$$\n\n$$\\beta_1 \\sim uniform(1, 3)$$\n\n$$\\beta_2 \\sim uniform(0.5, 2)$$\n\n$$\\sigma \\sim Gamma(2, 2)$$\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(567)\nb0_try <- runif(1, 4, 6)  # Parameter model\nb1_try <- runif(1, 1, 3)  # Parameter model \nb2_try <- rgamma(1, .5, 2) # Mathematical equation for process model\nmu_try <- b0_try + x*b1_try - (x^2)*b2_try\nsigma_try <- rgamma(1, 2, 2)\n```\n:::\n\n\n2.  Generate data with those parameters\\\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(567)\ny_try <- rnorm(n, mu_try, sigma_try)  # Process model\n```\n:::\n\n\n3.  Compare the simulated data with the observed data = \"difference\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Record difference between draw of y from prior predictive distribution and\n# observed data\ndiff[k, ] <- sum(abs(y - y_try))\n```\n:::\n\n\n\n\n4.  \"**Accept**\" (gold) that combination of parameters if the difference \\< predifined acceptable error. \"**Reject**\" (red) if the difference \\> predifined acceptable error.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(x, y, xlab = \"Plant density\", \n     ylab = \"Observed yield\", xlim = c(2, 13), ylim = c(5, 20),\n     typ = \"b\", cex = 0.8, pch = 20, col = rgb(0.7, 0.7, 0.7, 0.9))\npoints(x, y_hat[k,], typ = \"b\", lwd = 2, \n       col = ifelse(diff[1] < error, \"gold\", \"tomato\"))\n```\n\n::: {.cell-output-display}\n![](code_3_bayes_2_files/figure-html/demo 1e-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](code_3_bayes_2_files/figure-html/demo 1f-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](code_3_bayes_2_files/figure-html/demo 1g-1.png){width=672}\n:::\n:::\n\n\nNow, what if whe change the priors:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](code_3_bayes_2_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nNow, do many tries\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor (k in 1:K_tries) {\n    \n    b0_try <- runif(1, 2, 10)  # Parameter model\n    b1_try <- rnorm(1, 2.2, .5)  # Parameter model \n    b2_try <- rgamma(1, .25, 2) # Mathematical equation for process model\n    mu_try <- b0_try + x*b1_try - (x^2)*b2_try\n    sigma_try <- rgamma(1, 2, 2)\n\n    y_try <- rnorm(n, mu_try, sigma_try)  # Process model\n    \n    # Record difference between draw of y from prior predictive distribution and\n    # observed data\n    diff[k, ] <- sum(abs(y - y_try))\n    \n    # Save unkown random variables and parameters\n    y_hat[k, ] <- y_try\n    \n    posterior_samp_parameters[k, ] <- c(b0_try, b1_try, b2_try, sigma_try)\n}\n```\n:::\n\n\nAcceptance rate\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlength(which(diff < error))/K_tries\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.035985\n```\n:::\n:::\n\n\nPriors versus posteriors:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](code_3_bayes_2_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](code_3_bayes_2_files/figure-html/post 2-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](code_3_bayes_2_files/figure-html/post 3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(y_hat[which(diff < error), 25], col = \"grey\", freq = FALSE)\nabline(v = y[25], col = 'gold', lty = \"dashed\", lwd = 5)\n```\n\n::: {.cell-output-display}\n![](code_3_bayes_2_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](code_3_bayes_2_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nLet's get started\n\n## 2. Markov Chain Monte Carlo\n\n::: {align=\"center\"}\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Qqz5AJjyugM\" frameborder=\"0\" allowfullscreen>\n\n</iframe>\n:::\n\n## 3. brms: Bayesian Regression Models using \"Stan\"\n\n![](images/brms.png)\n\nDocumentation: <https://paul-buerkner.github.io/brms/>\n\nBug-reports: <https://github.com/paul-buerkner/brms/issues>\n\n*brms* is a very handy R-package that facilitates running Bayesian models using a relatively simple syntax. It is basically and interface that runs \"Stan\" behind the scenes. It uses a syntax quite similar to the [lme4](https://cran.r-project.org/package=lme4) package.\n\nIt allows to use several different type of distributions and link functions for models that are linear, counts, survival, response, ordinal, zero-inflated, etc.\n\nDue to its relatively simple syntax, today, we are going to start our Bayesian coding with brms.\n\nMore about brms at <https://www.jstatsoft.org/article/view/v080i01>\n\n![](images/paste-6C740B97.png){width=\"336\"}\n\n## 4. rstan: R interface to \"Stan\"\n\n![](images/stanlogo.png){width=\"190\"}\n\nDocumentation: <https://mc-stan.org/rstan/>\n\nBug reports: <https://github.com/stan-dev/rstan/issues/>\n\n*stan* is a stand-alone open-source software platform designed for statistical modeling using high-performance statistical computation applying its own language. When selecting the Bayesian computational approach (i.e. ***rejection sampling criteria***) there are several alternatives to choose. *Stan* produces Bayesian statistical inference following Hamiltonian Monte Carlo (HMC), and No-U-Turn Samples (NUTS). Besides R, *stan* has interfaces with other popular languages such as Python, MATLAB, Julia.\n\nIn contrast to *brms*, stan's syntax is more complicated for begginers, but the positive side is that requires us to write the statistical model.\n\nWe will not fit a model directly with stan today, but *brms* brings a function that allows users to obtain the code to run the analysis by ourselves using rstan. Let's see...\n\n## 5. rjags: R interface to \"Just Another Gibbs Sampler\"\n\n![](images/stanlogo.png){width=\"190\"}\n\nDocumentation: <https://mcmc-jags.sourceforge.io/>\n\nBug reports: <https://sourceforge.net/projects/mcmc-jags/>\n\n*rjags* is another popular option for Bayesian statistical inference following MCMC using R. *Rjags* produces Bayesian statistical inference following BUGS language (WinBUGS). Similar to *stan*, *rjags* it is probably not for beginner, since it requires us to write out the statistical model (although it is always ideal). To extract the posteriors, it also requires [coda](https://cran.r-project.org/web/packages/coda/index.html), which is especially designed for summarizing and plotting MCMC simulations.\n",
    "supporting": [
      "code_3_bayes_2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}